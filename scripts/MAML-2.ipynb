{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import torch\n",
    "\n",
    "DATASETS = '../datasets/'\n",
    "\n",
    "def read_file(dir_name):\n",
    "    main_df = pd.DataFrame()\n",
    "    directory = DATASETS + dir_name\n",
    "    for filename in os.listdir(directory):\n",
    "        data = np.load(os.path.join(directory, filename))\n",
    "        data_dict = {}\n",
    "        for keys in data.keys():\n",
    "            data_dict[keys] = list(data[keys])\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        main_df = pd.concat([main_df, df])\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw/cls_sweep-v2\n",
      "mw/cls_push-v2\n",
      "mw/cls_door-open-v2\n",
      "mw/cls_peg-insert-side-v2\n",
      "mw/cls_drawer-close-v2\n",
      "mw/cls_basketball-v2\n",
      "mw/cls_reach-v2\n",
      "mw/cls_window-open-v2\n",
      "mw/cls_pick-place-v2\n",
      "mw/cls_button_press_topdown-v2\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for name in os.listdir(\"../datasets/mw\"):\n",
    "    inner_df = pd.DataFrame()\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        inner_df = pd.concat([inner_df, df])    \n",
    "    data.append(inner_df)\n",
    "data = np.array(data, dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size = 2750):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.out = nn.Linear(hidden_size2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PreferenceMAML:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ml10,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        outer_lr,\n",
    "        inner_lr = 0.01,\n",
    "        num_support=10,\n",
    "        num_query=10,\n",
    "        num_inner_steps=5,\n",
    "        k = 25,\n",
    "        num_tasks = 10,\n",
    "        episode_per_task = 1250,\n",
    "        output_size = 2750,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.ml10 = ml10\n",
    "        self.reward_criterion =  nn.BCELoss()\n",
    "        self.num_support = num_support\n",
    "        self.num_query = num_query\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.inner_lr = inner_lr\n",
    "        self.outer_lr = outer_lr\n",
    "        self.k = k\n",
    "        self.num_tasks = num_tasks\n",
    "        self.episode_per_task = episode_per_task\n",
    "        self.num_segments = None\n",
    "        self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    def construct_episodes(self, ml10):\n",
    "        # episodes - n (tasks) x num_episode (each npz file)  , each cell is a dataframe of the episode \n",
    "        self.episodes = []\n",
    "        for task in ml10:\n",
    "            if(len(task)==0):\n",
    "                continue\n",
    "            task_episodes=[]\n",
    "            row_index = task[task['done'] == True].index.tolist()\n",
    "            prev=0\n",
    "            for x in row_index:\n",
    "                task_episodes.append(task[prev:x+1])\n",
    "                prev=x+1\n",
    "            task_episodes = np.array(task_episodes,dtype=object)\n",
    "            self.episodes.append(task_episodes)\n",
    "        self.episodes = np.array(self.episodes,dtype=object)\n",
    "        # return episodes\n",
    "\n",
    "    def form_sigma_groups(self, episode):\n",
    "        #num_segments = int(episode.shape[0] / self.k)\n",
    "        split_indices = np.arange(self.k, episode.shape[0], self.k)\n",
    "        # print(num_segments)\n",
    "        if len(split_indices) != 0:\n",
    "            l_segment = np.array_split(episode.iloc[::-1][:(self.k*(episode.shape[0] // self.k))], split_indices)\n",
    "            for i in range(len(l_segment)):\n",
    "                l_segment[i] = l_segment[i].iloc[::-1]\n",
    "            if(len(l_segment[-1])<25):\n",
    "                l_segment=l_segment[:-1]\n",
    "            return l_segment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def compare_probabilities(self, sigma1, sigma2):\n",
    "        exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "        exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "        prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "        return [0] if prob > 0.5 else [1]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        episodes = self.episodes\n",
    "        # sigmas = self.form_sigma_groups(episodes, k)\n",
    "        sigmas = []\n",
    "        for task in episodes:\n",
    "            sigma = []\n",
    "            for episode in task:\n",
    "                segment = self.form_sigma_groups(episode)\n",
    "                # print(len(segment))\n",
    "                if segment is not None:\n",
    "                    sigma.append(segment)\n",
    "            # sigma = [self.form_sigma_groups(episode, k) for episode in task]\n",
    "            sigmas.append(sigma)\n",
    "        sigmas = np.array(sigmas, dtype=object)\n",
    "        all_lengths = [len(episode) for task in sigmas for episode in task]\n",
    "\n",
    "        self.num_segments = min(all_lengths)\n",
    "        if(self.num_segments<3):\n",
    "            self.num_segments=3\n",
    "        \n",
    "        for task in sigmas:\n",
    "            task_list=[]\n",
    "            for episode in task:\n",
    "                ep_list=[]\n",
    "                if(len(episode)<self.num_segments):\n",
    "                    continue\n",
    "                for i in range(self.num_segments):\n",
    "                    y.append(episode[i][\"reward\"])\n",
    "                    ep_list.append(episode[i].drop('reward', axis=1))\n",
    "                \n",
    "                task_list.append(ep_list)\n",
    "            task_list=np.array(task_list, dtype=object).reshape(-1,1) # convert row vector to col vector\n",
    "            X.append(task_list)\n",
    "        X_new=[]\n",
    "        task_counter = []\n",
    "        for task in X:\n",
    "            counter = 0\n",
    "            for i in range(0,len(task),4):\n",
    "                X_new.append(np.concatenate((task[i][0], task[i+1][0])))\n",
    "                counter += 1\n",
    "            task_counter.append(counter)\n",
    "\n",
    "        X = np.array(X_new, dtype=object)\n",
    "        task_counts = np.array(task_counter, dtype=object)\n",
    "        y=np.array(y,dtype=object)\n",
    "        y=y.flatten()\n",
    "        #X=X.reshape(-1,1) # convert row vector to col vector\n",
    "\n",
    "\n",
    "        # All row vectors now, just transpose to make column vectors\n",
    "        \n",
    "\n",
    "            # sigmas = self.form_sigma_groups(episode, k)\n",
    "            # for _ in range(len(sigmas)):\n",
    "            #     sigma1 = sigmas[_][0]\n",
    "            #     sigma2 = sigmas[_][1]\n",
    "\n",
    "            #     obs_action_sigma1 = []\n",
    "            #     for row in sigma1:\n",
    "            #         obs_action = list(row['obs']) + list(row['action']) \n",
    "            #         obs_action_sigma1.append(obs_action)\n",
    "\n",
    "            #     obs_action_sigma2 = []\n",
    "            #     for row in sigma2:\n",
    "            #         obs_action = list(row['obs']) + list(row['action'])  \n",
    "            #         obs_action_sigma2.append(obs_action)\n",
    "\n",
    "            #     if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "            #         obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "            #     elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "            #         obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "            #     else:\n",
    "            #         continue\n",
    "\n",
    "            #     X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "            #     y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "        return X, y, task_counts\n",
    "    \n",
    "    def batchify(self, X, y, task_lengths, task_no, num=110):\n",
    "        # print(task_no)\n",
    "        if task_no == 0:\n",
    "            task_beg = 0  \n",
    "            task_end = task_lengths[0]\n",
    "        else:    \n",
    "            task_beg = np.sum(task_lengths[0:task_no])    \n",
    "            task_end = np.sum(task_lengths[0:task_no+1])\n",
    "        rand = random.sample(range(0,400), 110)\n",
    "        X_task = X[task_beg:task_end]\n",
    "        y_task = y[task_beg:task_end]\n",
    "        X_random = []\n",
    "        y_random = []\n",
    "        for r in rand:\n",
    "            X_random.append(X_task[r*25 : r*25+25])\n",
    "            y_random.append(y_task[r*25 : r*25+25])\n",
    "        X_random = np.array(X_random, dtype=np.float32)\n",
    "        y_random = np.array(y_random, dtype=np.float32)\n",
    "        return X_random.reshape(2750,43), y_random.reshape(2750,)\n",
    "    \n",
    "    def train(self, X, y, task_lengths, num_epochs):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.outer_lr)\n",
    "        optimizer.zero_grad()\n",
    "        plt_x = np.arange(0, num_epochs)\n",
    "        plt_y = np.zeros(num_epochs)\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            loss = []\n",
    "            for t in range(self.num_tasks):\n",
    "                # print(t)\n",
    "                X_b, y_b = self.batchify(X, y, task_lengths, t)\n",
    "                model_t = copy.deepcopy(self.model)\n",
    "                model_t = self._inner_loop(model_t, X_b, y_b)\n",
    "                loss.append(self._compute_loss(model_t, X_b, y_b))\n",
    "\n",
    "                # print(f\"Epoch {epoch+1}/{num_epochs} - Task {t+1}/{self.num_tasks}\")\n",
    "            out = loss[0]\n",
    "            for i in range(1, len(loss)):\n",
    "                out += loss[i]\n",
    "            plt_y[epoch] = out\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss}')\n",
    "                plt.plot(plt_x, plt_y)\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            out.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    # def _train_step(self, X, y):\n",
    "    #     self.optim.zero_grad()\n",
    "    #     loss = self._outer_step(X, y)\n",
    "    #     loss.backward()\n",
    "    #     self.optim.step()\n",
    "    #     return loss.item()\n",
    "\n",
    "    # def _outer_step(self, X, y):\n",
    "    #     outer_losses = []\n",
    "    #     for i in tqdm(range(len(X))):\n",
    "    #         if len(X[i])>self.num_support:\n",
    "    #             support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "    #             # Inner loop (adaptation)\n",
    "    #             adapted_model = self._inner_loop(support_X, support_y)\n",
    "    #             # Compute loss using the adapted model on query set\n",
    "    #             query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "    #             outer_losses.append(query_loss)\n",
    "    #     return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "    def _inner_loop(self, model, X, y):\n",
    "        loss = self._compute_loss(model, X, y)\n",
    "        opt = optim.Adam(model.parameters(), lr=self.inner_lr)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        return model\n",
    "    '''\n",
    "    R_E = \n",
    "    [\n",
    "        [\n",
    "            sigma_s1^E1, ..., sigma_s#^E1\n",
    "        ],\n",
    "        [\n",
    "            sigma_s1^E2, ..., sigma_s#^E2\n",
    "        ], ...,\n",
    "        [\n",
    "            sigma_s1^EN, ..., sigma_s#^EN\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    #self.k = segment lenght\n",
    "    def _compute_loss(self, model, X, y):\n",
    "        # print(X, y, X.shape, y.shape)\n",
    "        X_tensor = torch.from_numpy(X)\n",
    "        y_tensor = torch.from_numpy(y)  \n",
    "        output_reward = model(X_tensor)\n",
    "        N_o, _ = output_reward.shape\n",
    "        # print(output_reward.shape)\n",
    "        x =  y_tensor.shape[0]\n",
    "        N = x//self.k\n",
    "        out_mat = np.zeros((N, 1))\n",
    "        y_mat = np.zeros((N, 1))\n",
    "\n",
    "        for i in range(N):\n",
    "            # print(torch.sum(output_reward[i*self.k:(i+1)*self.k]).detach().numpy())\n",
    "            out_mat[i, :] = torch.sum(output_reward[i*self.k:(i+1)*self.k]).detach().numpy()\n",
    "            y_mat[i, :] = torch.sum(y_tensor[i*self.k:(i+1)*self.k]).detach().numpy()\n",
    "        \n",
    "        loss = []\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        out_mat = np.exp(out_mat)\n",
    "        for i in range(N):\n",
    "            sig_1 = out_mat[i, 0]\n",
    "            y_1 = y_mat[i, 0]\n",
    "            for j in range(i+1, N):\n",
    "                sig_2 = out_mat[j, 0]\n",
    "                y_2 = y_mat[j, 0]\n",
    "                out_jk = criterion(torch.tensor([sig_1], requires_grad=True), torch.tensor([sig_2], requires_grad= True))\n",
    "                if (y_1 >= y_2):\n",
    "                    loss.append(out_jk)\n",
    "                else:\n",
    "                    loss.append(1 - out_jk)\n",
    "        output = loss[0]\n",
    "        for i in range(1, len(loss)):\n",
    "            output += loss[i]\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "ml10 = data.copy()  \n",
    "input_size = 43  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 512\n",
    "# hidden_size3 = 1024\n",
    "# hidden_size4 = 2075\n",
    "\n",
    "output_size = 1\n",
    "num_epochs = 5\n",
    "outer_lr = 0.001\n",
    "\n",
    "model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, outer_lr=outer_lr)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "model.construct_episodes(ml10)\n",
    "print('Preparing Data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, task_lengths = model.prepare_data()\n",
    "print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: [tensor(29477., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2717., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3002., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2999., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3099., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2559., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3061., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2958., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(2627., dtype=torch.float64, grad_fn=<AddBackward0>), tensor(3285., dtype=torch.float64, grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 9/10000 [01:14<22:48:03,  8.22s/it]"
     ]
    }
   ],
   "source": [
    "model.train(X, y, task_lengths, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw_valid/cls_lever-pull-v2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(dir_name)\n\u001b[1;32m      6\u001b[0m         df \u001b[38;5;241m=\u001b[39m read_file(dir_name)\n\u001b[0;32m----> 7\u001b[0m         test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m Test \u001b[38;5;241m=\u001b[39m PreferenceMAML(test, input_size, hidden_size1, hidden_size2, output_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/few-shot-pref-rl/lib/python3.8/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/few-shot-pref-rl/lib/python3.8/site-packages/pandas/core/reshape/concat.py:462\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    458\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         )\n\u001b[0;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    464\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "for name in os.listdir(\"../datasets/mw_valid\"):\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw_valid/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        test = pd.concat([data, df])\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "Test = PreferenceMAML(test, input_size, hidden_size1, hidden_size2, output_size)\n",
    "test_X, test_y = Test.prepare_data(k=4)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            X_tensor = torch.tensor(X[i], dtype=torch.float32)\n",
    "            output = model.model(X_tensor.unsqueeze(0))  \n",
    "            predictions.append(output.squeeze().numpy())  \n",
    "\n",
    "    preds = []\n",
    "    for _ in range(len(predictions)):\n",
    "        preds.append((np.array(predictions[_]).mean()))\n",
    "\n",
    "    pred_label = []\n",
    "    for i in range(len(preds)):\n",
    "        pred_label.append([0] if preds[i]>0.5 else [1])\n",
    "    \n",
    "    sum = 0\n",
    "    for _ in range(len(y)):\n",
    "        sum += pred_label[_]==y[_]\n",
    "    accuracy = sum/len(y)\n",
    "    return accuracy, pred_label\n",
    "\n",
    "test_accuracy, pred_labels = evaluate_model(model, test_X, test_y)\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without INNER LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis = 1))\n",
    "#                 y.append([self.compare_probabilities(sigma1, sigma2)]) \n",
    "\n",
    "#         return X, y\n",
    "\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in range(len(X)):\n",
    "#             loss = self._compute_loss(X[i], y[i])\n",
    "#             outer_losses.append(loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _compute_loss(self, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_tensor = torch.tensor([y], dtype=torch.float32)\n",
    "#         output = self.model(X_tensor)\n",
    "#         output_flat = output.view(-1)\n",
    "#         y_flat = y_tensor.view(-1)\n",
    "#         loss = self.reward_criterion(output_flat[-2:], y_flat)\n",
    "#         return loss\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 20\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": 0.005})\n",
    "\n",
    "# X, y = model.prepare_data(k=4)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With INNER LOOP but Improper classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         inner_lr = 0.01,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "#         self.inner_lr = inner_lr\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "#                 y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in tqdm(range(len(X))):\n",
    "#             if len(X[i])>self.num_support:\n",
    "#                 support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "#                 # Inner loop (adaptation)\n",
    "#                 adapted_model = self._inner_loop(support_X, support_y)\n",
    "#                 # Compute loss using the adapted model on query set\n",
    "#                 query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "#                 outer_losses.append(query_loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _inner_loop(self, support_X, support_y):\n",
    "#         adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "#                               self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "#         adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "#         inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "#         for _ in range(self.num_inner_steps):\n",
    "#             inner_optimizer.zero_grad()\n",
    "#             loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "#             inner_optimizer.step()\n",
    "\n",
    "#         return adapted_model\n",
    "\n",
    "#     def _compute_loss(self, model, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_class = [0 if y[i]==[1,0] else 1 for i in range(len(y))]\n",
    "#         y_tensor = torch.tensor(y_class, dtype=torch.long)  # Assuming y is class indices\n",
    "#         output = model(X_tensor)\n",
    "\n",
    "#         loss = self.reward_criterion(output, y_tensor)\n",
    "#         return loss\n",
    "\n",
    "#     def _split_support_query(self, X, y):\n",
    "#         num_samples = len(X)\n",
    "#         all_indices = np.arange(num_samples)\n",
    "#         # Randomly sample support indices\n",
    "#         support_indices = np.random.choice(num_samples, self.num_support, replace=False)\n",
    "#         query_indices = np.setdiff1d(all_indices, support_indices)\n",
    "#         support_X = X[support_indices]\n",
    "#         query_X = X[query_indices]\n",
    "#         # For y, we can simply use the same indices as for X, as it has a fixed length of 2\n",
    "#         support_y = [y] * self.num_support\n",
    "#         query_y = [y] * len(query_indices)\n",
    "\n",
    "#         return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 5\n",
    "# outer_lr = 0.001\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "# print('Preparing Data.')\n",
    "# # X, y = model.prepare_data(k=4)\n",
    "# print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
