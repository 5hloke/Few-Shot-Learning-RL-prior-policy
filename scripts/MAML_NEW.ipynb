{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import torch\n",
    "\n",
    "DATASETS = '../datasets/'\n",
    "\n",
    "def read_file(dir_name):\n",
    "    main_df = pd.DataFrame()\n",
    "    directory = DATASETS + dir_name\n",
    "    for filename in os.listdir(directory):\n",
    "        data = np.load(os.path.join(directory, filename))\n",
    "        data_dict = {}\n",
    "        for keys in data.keys():\n",
    "            data_dict[keys] = list(data[keys])\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        main_df = pd.concat([main_df, df])\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw/cls_sweep-v2\n",
      "mw/cls_push-v2\n",
      "mw/cls_door-open-v2\n",
      "mw/cls_peg-insert-side-v2\n",
      "mw/cls_drawer-close-v2\n",
      "mw/cls_basketball-v2\n",
      "mw/cls_reach-v2\n",
      "mw/cls_window-open-v2\n",
      "mw/cls_pick-place-v2\n",
      "mw/cls_button_press_topdown-v2\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for name in os.listdir(\"../datasets/mw\"):\n",
    "    inner_df = pd.DataFrame()\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        inner_df = pd.concat([inner_df, df])    \n",
    "    data.append(inner_df)\n",
    "data = np.array(data, dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PreferenceMAML:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ml10,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        output_size,\n",
    "        inner_lr = 0.01,\n",
    "        num_support=10,\n",
    "        num_query=10,\n",
    "        num_inner_steps=5,\n",
    "        k = 25,\n",
    "        num_tasks = 10,\n",
    "        episode_per_task = 1250,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.ml10 = ml10\n",
    "        self.reward_criterion =  nn.BCELoss()\n",
    "        self.num_support = num_support\n",
    "        self.num_query = num_query\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.inner_lr = inner_lr\n",
    "        self.k = k\n",
    "        self.num_tasks = num_tasks\n",
    "        self.episode_per_task = episode_per_task\n",
    "        self.num_segments = None\n",
    "        self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    def construct_episodes(self, ml10):\n",
    "        # episodes - n (tasks) x num_episode (each npz file)  , each cell is a dataframe of the episode \n",
    "        self.episodes = []\n",
    "        \n",
    "        for task in ml10:\n",
    "            task_episodes=[]\n",
    "            row_index = task[task['done'] == True].index.tolist()\n",
    "            prev=0\n",
    "            for x in row_index:\n",
    "                task_episodes.append(task[prev:x+1])\n",
    "                prev=x+1\n",
    "            task_episodes = np.array(task_episodes,dtype=object)\n",
    "            self.episodes.append(task_episodes)\n",
    "        self.episodes = np.array(self.episodes,dtype=object)\n",
    "        # return episodes\n",
    "\n",
    "    def form_sigma_groups(self, episode):\n",
    "        num_segments = int(episode.shape[0] / self.k)\n",
    "        # print(num_segments)\n",
    "        if num_segments != 0:\n",
    "            l_segment = np.array_split(episode.iloc[::-1], num_segments)\n",
    "            for i in range(len(l_segment)):\n",
    "                l_segment[i] = l_segment[i].iloc[::-1]\n",
    "            return l_segment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def compare_probabilities(self, sigma1, sigma2):\n",
    "        exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "        exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "        prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "        return [0] if prob > 0.5 else [1]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        episodes = self.episodes\n",
    "        # sigmas = self.form_sigma_groups(episodes, k)\n",
    "        sigmas = []\n",
    "        for task in episodes:\n",
    "            sigma = []\n",
    "            for episode in task:\n",
    "                segment = self.form_sigma_groups(episode)\n",
    "                # print(len(segment))\n",
    "                if segment is not None:\n",
    "                    sigma.append(segment)\n",
    "            # sigma = [self.form_sigma_groups(episode, k) for episode in task]\n",
    "            sigmas.append(sigma)\n",
    "        sigmas = np.array(sigmas, dtype=object)\n",
    "        # for task in sigmas:\n",
    "        #     for episode in task:\n",
    "        #         print(len(episode))\n",
    "            # sigmas = self.form_sigma_groups(episode, k)\n",
    "            # for _ in range(len(sigmas)):\n",
    "            #     sigma1 = sigmas[_][0]\n",
    "            #     sigma2 = sigmas[_][1]\n",
    "\n",
    "            #     obs_action_sigma1 = []\n",
    "            #     for row in sigma1:\n",
    "            #         obs_action = list(row['obs']) + list(row['action']) \n",
    "            #         obs_action_sigma1.append(obs_action)\n",
    "\n",
    "            #     obs_action_sigma2 = []\n",
    "            #     for row in sigma2:\n",
    "            #         obs_action = list(row['obs']) + list(row['action'])  \n",
    "            #         obs_action_sigma2.append(obs_action)\n",
    "\n",
    "            #     if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "            #         obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "            #     elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "            #         obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "            #     else:\n",
    "            #         continue\n",
    "\n",
    "            #     X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "            #     y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "        return X, y, sigmas\n",
    "\n",
    "    def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "        self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "    def _train_step(self, X, y):\n",
    "        self.optim.zero_grad()\n",
    "        loss = self._outer_step(X, y)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def _outer_step(self, X, y):\n",
    "        outer_losses = []\n",
    "        for i in tqdm(range(len(X))):\n",
    "            if len(X[i])>self.num_support:\n",
    "                support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "                # Inner loop (adaptation)\n",
    "                adapted_model = self._inner_loop(support_X, support_y)\n",
    "                # Compute loss using the adapted model on query set\n",
    "                query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "                outer_losses.append(query_loss)\n",
    "        return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "    def _inner_loop(self, support_X, support_y):\n",
    "        adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "                              self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "        adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "        inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "        for _ in range(self.num_inner_steps):\n",
    "            inner_optimizer.zero_grad()\n",
    "            loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "            loss.backward()\n",
    "            inner_optimizer.step()\n",
    "\n",
    "        return adapted_model\n",
    "    '''\n",
    "    R_E = \n",
    "    [\n",
    "        [\n",
    "            sigma_s1^E1, ..., sigma_s#^E1\n",
    "        ],\n",
    "        [\n",
    "            sigma_s1^E2, ..., sigma_s#^E2\n",
    "        ], ...,\n",
    "        [\n",
    "            sigma_s1^EN, ..., sigma_s#^EN\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    #self.k = segment lenght\n",
    "    def _compute_loss(self, model, X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)  \n",
    "        output_reward = model(X_tensor)\n",
    "        N_o, _ = output_reward.shape\n",
    "        out_mat = np.zeros(self.num_tasks, self.episode_per_tasks, self.num_segments)\n",
    "        y_mat = np.zeros(self.num_tasks, self.episode_per_tasks, self.num_segments)\n",
    "\n",
    "        T = self.episode_per_task*self.k*self.num_segments\n",
    "        for i in range(0, output_reward.shape[0], self.k):\n",
    "            ind = i % T\n",
    "            task_num = i // T\n",
    "            ep = ind // (self.num_segments * self.k)\n",
    "            seg = ind % (self.num_segments * self.k)\n",
    "            out_mat[task_num, ep, seg] = np.sum(output_reward[i : i+self.k])\n",
    "            y_mat[task_num, ep, seg ] = np.sum(y_tensor[i: i+self.k])\n",
    "        \n",
    "        loss = 0.0\n",
    "        for i in range(self.num_tasks):\n",
    "            for j in range(self.num_segments):\n",
    "                for k in range(j, self.num_segments):\n",
    "                    out_seg_j = out_mat[i, :, j].squeeze()\n",
    "                    out_seg_k = out_mat[i, :, k].squeeze()\n",
    "                    y_seg_j = y_mat[i, :, j].squeeze()\n",
    "                    y_seg_k = y_mat[i, :, k].squeeze() \n",
    "\n",
    "                    # comparison\n",
    "                    exp_j = np.exp(out_seg_j)\n",
    "                    exp_k = np.exp(out_seg_k)\n",
    "                    out_jk = exp_j / (exp_j + exp_k)\n",
    "                    if (y_seg_j >= y_seg_k):\n",
    "                        loss += -np.log(out_jk)\n",
    "                    else:\n",
    "                        loss += -np.log(1 - out_jk)\n",
    "        return loss\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "ml10 = data.copy()  \n",
    "input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 128\n",
    "output_size = 1\n",
    "num_epochs = 5\n",
    "outer_lr = 0.001\n",
    "\n",
    "model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "model.construct_episodes(ml10)\n",
    "print('Preparing Data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, sigmas = model.prepare_data()\n",
    "print('Data Preparation Done.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRYING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(RewardPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "reward_model = RewardPredictor(input_size=43, hidden_size1=128, hidden_size2=128, output_size=1)\n",
    "optimizer = optim.Adam(reward_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPROACH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1226/1226 [00:15<00:00, 77.44it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:12<00:00, 98.25it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:16<00:00, 72.40it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:20<00:00, 60.17it/s]\n",
      "100%|███████████████████████████████████████| 1202/1202 [00:13<00:00, 87.22it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:22<00:00, 53.96it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:10<00:00, 119.81it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:14<00:00, 87.41it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:10<00:00, 116.41it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:11<00:00, 104.52it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:22<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "105.35837144511184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1226/1226 [00:13<00:00, 87.72it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:11<00:00, 104.55it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:16<00:00, 75.69it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:20<00:00, 59.45it/s]\n",
      "100%|███████████████████████████████████████| 1202/1202 [00:13<00:00, 86.81it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:17<00:00, 71.88it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:08<00:00, 143.59it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:13<00:00, 90.35it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:09<00:00, 127.12it/s]\n",
      "100%|██████████████████████████████████████| 1226/1226 [00:11<00:00, 105.69it/s]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:22<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "105.35837144511184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on each segment separately for \"inner_epochs\" times\n",
    "\n",
    "def _inner_loop(sigmas):\n",
    "    for tasks in sigmas:\n",
    "        for episode in tqdm(tasks):\n",
    "\n",
    "            for segments in episode:\n",
    "\n",
    "                obs_action = np.hstack((segments['obs'].values.tolist(), segments['action'].values.tolist()))\n",
    "                reward = torch.tensor(segments['reward'].values.tolist())\n",
    "\n",
    "                for inner_epoch in range(5): # inner_epochs   \n",
    "                    segments['reward_pred'] = 0\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = reward_model(torch.tensor(obs_action))\n",
    "                    segments['reward_pred'] = outputs.tolist()\n",
    "                    loss = criterion(outputs, reward) \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "    return model, sigmas\n",
    "\n",
    "\n",
    "for outer_epoch in range(2): # outer epochs # pointless. keep 1\n",
    "    outer_losses = []\n",
    "\n",
    "    m,sigmas = _inner_loop(sigmas)\n",
    "\n",
    "    pref_loss_list = []\n",
    "\n",
    "    for i in tqdm(range(len(sigmas))):\n",
    "        for j in  range ( len (sigmas[i])//8 ) : # //8 to reduce compute time ## Need to optimize\n",
    "\n",
    "            outer_loss = 0\n",
    "            \n",
    "            rewards_1 = 0\n",
    "            reward_pred_1 = 0\n",
    "            for seg1 in sigmas[i][j]:\n",
    "                rewards_1 += seg1['reward'].sum()\n",
    "                reward_pred_1 += np.array(seg1['reward_pred'].values.tolist()).flatten().sum()\n",
    "            \n",
    "            \n",
    "            for k in range(len(sigmas[i])//8):\n",
    "                rewards_2 = 0\n",
    "                reward_pred_2 = 0\n",
    "                if j!=k:\n",
    "                    for seg2 in s[i][k]:\n",
    "                        # if c==0:\n",
    "                        #     print(np.array(seg2['reward_pred'].values.tolist()).flatten().sum())\n",
    "                        #     c+=1\n",
    "                        rewards_2 += seg2['reward'].sum()\n",
    "                        reward_pred_2 += np.array(seg2['reward_pred'].values.tolist()).flatten().sum()\n",
    "\n",
    "                    p_reward_pred = np.exp(reward_pred_1) / ( np.exp(reward_pred_1) + np.exp(reward_pred_2) )\n",
    "\n",
    "                    # print('reward1 = ',rewards_1)\n",
    "                    # print('reward2 = ',rewards_2)\n",
    "\n",
    "                    if rewards_1 >= rewards_2:\n",
    "                        outer_loss += -np.log(1 - p_reward_pred)\n",
    "                    else:\n",
    "                        outer_loss += -np.log(p_reward_pred) \n",
    "\n",
    "            pref_loss_list.append(outer_loss)\n",
    "\n",
    "                \n",
    "    # loss = _compute_loss(model, x,y)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    print(np.mean(pref_loss_list))\n",
    "    print(outer_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPROACH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1226/1226 [00:35<00:00, 34.56it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:28<00:00, 43.26it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:38<00:00, 32.07it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:45<00:00, 26.74it/s]\n",
      "100%|███████████████████████████████████████| 1202/1202 [00:32<00:00, 37.41it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:41<00:00, 29.79it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:19<00:00, 63.48it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:31<00:00, 38.56it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:23<00:00, 52.67it/s]\n",
      "100%|███████████████████████████████████████| 1226/1226 [00:29<00:00, 41.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b68c6d50>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training for each segment \"inner_epochs\" times and getting rolled up predicted and actual rewards at a task level for each epoch\n",
    "#### Training at a segment level becauce flattening all of X and training in one go was crashing kernel\n",
    "\n",
    "inner_epochs = 10\n",
    "\n",
    "def _inner_loop(sigmas):\n",
    "    task_rewards = []\n",
    "    task_rewards_actual = []\n",
    "    for tasks in sigmas:\n",
    "        episode_rewards = []\n",
    "        episode_rewards_actual = []\n",
    "        for episode in tqdm(tasks):\n",
    "            segments_reward = []\n",
    "            segments_reward_actual = []\n",
    "            for segments in episode:\n",
    "                seg_reward = []\n",
    "                seg_reward_actual = []\n",
    "                obs_action = np.hstack((segments['obs'].values.tolist(), segments['action'].values.tolist()))\n",
    "                reward = torch.tensor(segments['reward'].values.tolist())\n",
    "                for inner_epoch in range(inner_epochs): # inner_epochs   \n",
    "                    segments['reward_pred'] = 0\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = reward_model(torch.tensor(obs_action))\n",
    "                    segments['reward_pred'] = outputs.tolist()\n",
    "                    loss = criterion(outputs, reward) \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    seg_reward.append(np.sum([i[0] for i in outputs.tolist()]))\n",
    "                    seg_reward_actual.append(np.sum(segments['reward']))\n",
    "                segments_reward.append(seg_reward)\n",
    "                segments_reward_actual.append(seg_reward_actual)                   \n",
    "            episode_rewards.append(seg_reward)\n",
    "            episode_rewards_actual.append(seg_reward_actual) \n",
    "        task_rewards.append(episode_rewards)\n",
    "        task_rewards_actual.append(episode_rewards_actual)\n",
    "        \n",
    "    return model, sigmas, task_rewards, task_rewards_actual\n",
    "\n",
    "\n",
    "\n",
    "m,sigmas, t_r, t_r_actual = _inner_loop(sigmas)\n",
    "\n",
    "\n",
    "## Using the rolled up rewards generated in previous step and getting preference loss\n",
    "### Plot shows mean loss for all segment pairs. (ignored the NaNs and inf but there are many)\n",
    "\n",
    "seg_pair_loss = []\n",
    "\n",
    "for ep in range(inner_epochs):\n",
    "    for i in range(len(t_r)):\n",
    "        for j in  range ( len (t_r[i])//8 ) : # //8 to reduce compute time ## Need to optimize\n",
    "            rewards_1 = t_r_actual[i][j][ep]\n",
    "            reward_pred_1 = t_r[i][j][ep]\n",
    "            for k in range(len(t_r[i])//8):\n",
    "                if j!=k:\n",
    "                    rewards_2 = t_r_actual[i][k][ep]\n",
    "                    reward_pred_2 = t_r[i][k][ep]\n",
    "                    p_reward_pred = np.exp(reward_pred_1) / ( np.exp(reward_pred_1) + np.exp(reward_pred_2) )\n",
    "                    if rewards_1 >= rewards_2:\n",
    "                        seg_pair_loss.append(-np.log(1 - p_reward_pred))\n",
    "                    else:\n",
    "                        seg_pair_loss.append(-np.log(p_reward_pred))\n",
    "                \n",
    "        \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "a = np.array(seg_pair_loss)\n",
    "b=[]\n",
    "parts = int(len(a)/inner_epochs)\n",
    "for i in range(inner_epochs):\n",
    "    b.append(a[i:i+parts])\n",
    "c = np.array(b)\n",
    "e = []\n",
    "for _ in range(inner_epochs):\n",
    "    d = c[_]\n",
    "    e.append(np.mean(d[np.isfinite(d)]))\n",
    "plt.plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "      <th>discount</th>\n",
       "      <th>reward_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>[0.034663986, 0.5243422, 0.1703135, 0.29937088...</td>\n",
       "      <td>[-9.797433, -0.17872009, -0.6345683, 0.46060854]</td>\n",
       "      <td>4.328230</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.562683582305908]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>[0.030240217, 0.519522, 0.16670175, 0.299476, ...</td>\n",
       "      <td>[-9.523514, 0.10737329, -0.28555673, 0.5173553]</td>\n",
       "      <td>4.469800</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.577765941619873]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>[0.024245242, 0.5166351, 0.16294265, 0.2995267...</td>\n",
       "      <td>[-9.39916, 0.13828787, -0.19460854, 0.72149044]</td>\n",
       "      <td>4.651777</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.5553741455078125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>[0.017095169, 0.51546377, 0.15935105, 0.299493...</td>\n",
       "      <td>[-9.295212, 0.28544623, -0.14577521, 0.76571876]</td>\n",
       "      <td>4.876531</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.548862457275391]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>[0.009148297, 0.515637, 0.15615515, 0.29966816...</td>\n",
       "      <td>[-9.170569, 0.12306155, 0.055366706, 0.5336315]</td>\n",
       "      <td>5.140619</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.558046817779541]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>[0.0006667477, 0.5166879, 0.15349181, 0.300020...</td>\n",
       "      <td>[-9.065167, 0.24371998, 0.025193242, 0.6179144]</td>\n",
       "      <td>5.435490</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.530896186828613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>[-0.0066282228, 0.51820445, 0.15152864, 0.3003...</td>\n",
       "      <td>[1.206173, 0.3480522, 0.20350617, 0.55256045]</td>\n",
       "      <td>5.698062</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.328176736831665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>[-0.010562294, 0.5197068, 0.1504444, 0.3003856...</td>\n",
       "      <td>[1.5497892, -0.050520375, 0.2747001, 0.6831771]</td>\n",
       "      <td>5.853446</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.8346567153930664]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>[-0.010860335, 0.5209627, 0.15025213, 0.300428...</td>\n",
       "      <td>[1.4952505, 0.2276854, 0.29635754, 0.45048678]</td>\n",
       "      <td>5.895344</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.53109073638916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>[-0.008076727, 0.52212185, 0.15080675, 0.30081...</td>\n",
       "      <td>[1.6421607, 0.32315052, 0.14952779, 0.6711741]</td>\n",
       "      <td>5.841106</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.3294448852539062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>[-0.0029945148, 0.5232971, 0.15177721, 0.30010...</td>\n",
       "      <td>[1.4728601, 0.37481734, 0.06001007, 0.70068395]</td>\n",
       "      <td>5.708635</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.2084884643554688]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>[0.0037298752, 0.5244071, 0.15291774, 0.299338...</td>\n",
       "      <td>[1.2893327, -0.02874771, 0.1969084, 0.5314483]</td>\n",
       "      <td>5.510235</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.7276575565338135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>[0.011564481, 0.5251701, 0.15401158, 0.2991888...</td>\n",
       "      <td>[1.0801308, 0.008876859, -0.03801094, 0.67585284]</td>\n",
       "      <td>5.259593</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.556769371032715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>[0.01858691, 0.5259739, 0.1548947, 0.29923016,...</td>\n",
       "      <td>[-9.125503, 0.22037752, 0.1923466, 0.64017814]</td>\n",
       "      <td>5.028327</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.578927040100098]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>[0.02262248, 0.5272865, 0.15563802, 0.29933757...</td>\n",
       "      <td>[-9.425161, 0.07619523, 0.25918043, 0.62027377]</td>\n",
       "      <td>4.894722</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.673454761505127]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>[0.023285406, 0.52892375, 0.15621382, 0.299384...</td>\n",
       "      <td>[-9.317774, 0.20842695, -0.014152869, 0.78939664]</td>\n",
       "      <td>4.867698</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.578579425811768]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>[0.02093729, 0.5305105, 0.15654376, 0.29941407...</td>\n",
       "      <td>[-9.379942, -0.07900277, 0.086348526, 0.61819595]</td>\n",
       "      <td>4.934854</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.604321002960205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>[0.01620819, 0.53168625, 0.15667993, 0.2995108...</td>\n",
       "      <td>[-9.296836, -0.049768817, -0.0057542967, 0.602...</td>\n",
       "      <td>5.081439</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.560731887817383]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>[0.009739172, 0.53238124, 0.1567868, 0.2996120...</td>\n",
       "      <td>[-9.199534, -0.12558584, 0.1891846, 0.62281126]</td>\n",
       "      <td>5.294136</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.566792964935303]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>[0.0020741604, 0.5326722, 0.15709871, 0.300017...</td>\n",
       "      <td>[-8.958145, -0.061428737, 0.1490052, 0.50706375]</td>\n",
       "      <td>5.558867</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.496324062347412]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>[-0.0064423922, 0.53252935, 0.15756984, 0.3004...</td>\n",
       "      <td>[-8.728643, -0.14991653, -0.045970254, 0.6544776]</td>\n",
       "      <td>5.852507</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.361785411834717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>[-0.0155276405, 0.53214264, 0.15818699, 0.3009...</td>\n",
       "      <td>[-8.589782, 0.094206154, 0.16897404, 0.45685154]</td>\n",
       "      <td>6.159506</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.412289619445801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>[-0.024960002, 0.5317294, 0.15899229, 0.301777...</td>\n",
       "      <td>[-8.418705, -0.06308933, 0.040710755, 0.67119175]</td>\n",
       "      <td>6.455325</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.300151348114014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>[-0.03461002, 0.5312206, 0.15983106, 0.301852,...</td>\n",
       "      <td>[-8.161527, -0.018656338, -0.0018882287, 0.568...</td>\n",
       "      <td>6.710538</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.225679874420166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>[-0.04439251, 0.530637, 0.16055506, 0.30126318...</td>\n",
       "      <td>[-7.9071984, 0.021326201, -0.06510902, 0.72060...</td>\n",
       "      <td>6.896173</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.127711296081543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>[-0.05422419, 0.5300636, 0.16112605, 0.3002303...</td>\n",
       "      <td>[-7.5098715, -0.024198977, 0.053040158, 0.5365...</td>\n",
       "      <td>6.991755</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.042862415313721]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>[-0.06405095, 0.5295082, 0.161556, 0.29992443,...</td>\n",
       "      <td>[-7.507612, -0.023289157, -0.028067105, 0.6164...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4.02456521987915]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    obs  \\\n",
       "1119  [0.034663986, 0.5243422, 0.1703135, 0.29937088...   \n",
       "1120  [0.030240217, 0.519522, 0.16670175, 0.299476, ...   \n",
       "1121  [0.024245242, 0.5166351, 0.16294265, 0.2995267...   \n",
       "1122  [0.017095169, 0.51546377, 0.15935105, 0.299493...   \n",
       "1123  [0.009148297, 0.515637, 0.15615515, 0.29966816...   \n",
       "1124  [0.0006667477, 0.5166879, 0.15349181, 0.300020...   \n",
       "1125  [-0.0066282228, 0.51820445, 0.15152864, 0.3003...   \n",
       "1126  [-0.010562294, 0.5197068, 0.1504444, 0.3003856...   \n",
       "1127  [-0.010860335, 0.5209627, 0.15025213, 0.300428...   \n",
       "1128  [-0.008076727, 0.52212185, 0.15080675, 0.30081...   \n",
       "1129  [-0.0029945148, 0.5232971, 0.15177721, 0.30010...   \n",
       "1130  [0.0037298752, 0.5244071, 0.15291774, 0.299338...   \n",
       "1131  [0.011564481, 0.5251701, 0.15401158, 0.2991888...   \n",
       "1132  [0.01858691, 0.5259739, 0.1548947, 0.29923016,...   \n",
       "1133  [0.02262248, 0.5272865, 0.15563802, 0.29933757...   \n",
       "1134  [0.023285406, 0.52892375, 0.15621382, 0.299384...   \n",
       "1135  [0.02093729, 0.5305105, 0.15654376, 0.29941407...   \n",
       "1136  [0.01620819, 0.53168625, 0.15667993, 0.2995108...   \n",
       "1137  [0.009739172, 0.53238124, 0.1567868, 0.2996120...   \n",
       "1138  [0.0020741604, 0.5326722, 0.15709871, 0.300017...   \n",
       "1139  [-0.0064423922, 0.53252935, 0.15756984, 0.3004...   \n",
       "1140  [-0.0155276405, 0.53214264, 0.15818699, 0.3009...   \n",
       "1141  [-0.024960002, 0.5317294, 0.15899229, 0.301777...   \n",
       "1142  [-0.03461002, 0.5312206, 0.15983106, 0.301852,...   \n",
       "1143  [-0.04439251, 0.530637, 0.16055506, 0.30126318...   \n",
       "1144  [-0.05422419, 0.5300636, 0.16112605, 0.3002303...   \n",
       "1145  [-0.06405095, 0.5295082, 0.161556, 0.29992443,...   \n",
       "\n",
       "                                                 action     reward   done  \\\n",
       "1119   [-9.797433, -0.17872009, -0.6345683, 0.46060854]   4.328230  False   \n",
       "1120    [-9.523514, 0.10737329, -0.28555673, 0.5173553]   4.469800  False   \n",
       "1121    [-9.39916, 0.13828787, -0.19460854, 0.72149044]   4.651777  False   \n",
       "1122   [-9.295212, 0.28544623, -0.14577521, 0.76571876]   4.876531  False   \n",
       "1123    [-9.170569, 0.12306155, 0.055366706, 0.5336315]   5.140619  False   \n",
       "1124    [-9.065167, 0.24371998, 0.025193242, 0.6179144]   5.435490  False   \n",
       "1125      [1.206173, 0.3480522, 0.20350617, 0.55256045]   5.698062  False   \n",
       "1126    [1.5497892, -0.050520375, 0.2747001, 0.6831771]   5.853446  False   \n",
       "1127     [1.4952505, 0.2276854, 0.29635754, 0.45048678]   5.895344  False   \n",
       "1128     [1.6421607, 0.32315052, 0.14952779, 0.6711741]   5.841106  False   \n",
       "1129    [1.4728601, 0.37481734, 0.06001007, 0.70068395]   5.708635  False   \n",
       "1130     [1.2893327, -0.02874771, 0.1969084, 0.5314483]   5.510235  False   \n",
       "1131  [1.0801308, 0.008876859, -0.03801094, 0.67585284]   5.259593  False   \n",
       "1132     [-9.125503, 0.22037752, 0.1923466, 0.64017814]   5.028327  False   \n",
       "1133    [-9.425161, 0.07619523, 0.25918043, 0.62027377]   4.894722  False   \n",
       "1134  [-9.317774, 0.20842695, -0.014152869, 0.78939664]   4.867698  False   \n",
       "1135  [-9.379942, -0.07900277, 0.086348526, 0.61819595]   4.934854  False   \n",
       "1136  [-9.296836, -0.049768817, -0.0057542967, 0.602...   5.081439  False   \n",
       "1137    [-9.199534, -0.12558584, 0.1891846, 0.62281126]   5.294136  False   \n",
       "1138   [-8.958145, -0.061428737, 0.1490052, 0.50706375]   5.558867  False   \n",
       "1139  [-8.728643, -0.14991653, -0.045970254, 0.6544776]   5.852507  False   \n",
       "1140   [-8.589782, 0.094206154, 0.16897404, 0.45685154]   6.159506  False   \n",
       "1141  [-8.418705, -0.06308933, 0.040710755, 0.67119175]   6.455325  False   \n",
       "1142  [-8.161527, -0.018656338, -0.0018882287, 0.568...   6.710538  False   \n",
       "1143  [-7.9071984, 0.021326201, -0.06510902, 0.72060...   6.896173  False   \n",
       "1144  [-7.5098715, -0.024198977, 0.053040158, 0.5365...   6.991755  False   \n",
       "1145  [-7.507612, -0.023289157, -0.028067105, 0.6164...  10.000000   True   \n",
       "\n",
       "      discount           reward_pred  \n",
       "1119       1.0   [4.562683582305908]  \n",
       "1120       1.0   [4.577765941619873]  \n",
       "1121       1.0  [4.5553741455078125]  \n",
       "1122       1.0   [4.548862457275391]  \n",
       "1123       1.0   [4.558046817779541]  \n",
       "1124       1.0   [4.530896186828613]  \n",
       "1125       1.0   [3.328176736831665]  \n",
       "1126       1.0  [3.8346567153930664]  \n",
       "1127       1.0    [3.53109073638916]  \n",
       "1128       1.0  [3.3294448852539062]  \n",
       "1129       1.0  [3.2084884643554688]  \n",
       "1130       1.0  [3.7276575565338135]  \n",
       "1131       1.0   [3.556769371032715]  \n",
       "1132       1.0   [4.578927040100098]  \n",
       "1133       1.0   [4.673454761505127]  \n",
       "1134       1.0   [4.578579425811768]  \n",
       "1135       1.0   [4.604321002960205]  \n",
       "1136       1.0   [4.560731887817383]  \n",
       "1137       1.0   [4.566792964935303]  \n",
       "1138       1.0   [4.496324062347412]  \n",
       "1139       1.0   [4.361785411834717]  \n",
       "1140       1.0   [4.412289619445801]  \n",
       "1141       1.0   [4.300151348114014]  \n",
       "1142       1.0   [4.225679874420166]  \n",
       "1143       1.0   [4.127711296081543]  \n",
       "1144       1.0   [4.042862415313721]  \n",
       "1145       1.0    [4.02456521987915]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3][9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw_valid/cls_shelf-place-v2\n",
      "mw_valid/cls_drawer-open-v2\n",
      "mw_valid/cls_lever-pull-v2\n",
      "mw_valid/cls_sweep-into-v2\n",
      "\n",
      "Test Accuracy: 0.6552772808586762\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "for name in os.listdir(\"../datasets/mw_valid\"):\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw_valid/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        test = pd.concat([data, df])\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "Test = PreferenceMAML(test, input_size, hidden_size1, hidden_size2, output_size)\n",
    "test_X, test_y = Test.prepare_data(k=4)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            X_tensor = torch.tensor(X[i], dtype=torch.float32)\n",
    "            output = model.model(X_tensor.unsqueeze(0))  \n",
    "            predictions.append(output.squeeze().numpy())  \n",
    "\n",
    "    preds = []\n",
    "    for _ in range(len(predictions)):\n",
    "        preds.append((np.array(predictions[_]).mean()))\n",
    "\n",
    "    pred_label = []\n",
    "    for i in range(len(preds)):\n",
    "        pred_label.append([0] if preds[i]>0.5 else [1])\n",
    "    \n",
    "    sum = 0\n",
    "    for _ in range(len(y)):\n",
    "        sum += pred_label[_]==y[_]\n",
    "    accuracy = sum/len(y)\n",
    "    return accuracy, pred_label\n",
    "\n",
    "test_accuracy, pred_labels = evaluate_model(model, test_X, test_y)\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without INNER LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis = 1))\n",
    "#                 y.append([self.compare_probabilities(sigma1, sigma2)]) \n",
    "\n",
    "#         return X, y\n",
    "\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in range(len(X)):\n",
    "#             loss = self._compute_loss(X[i], y[i])\n",
    "#             outer_losses.append(loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _compute_loss(self, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_tensor = torch.tensor([y], dtype=torch.float32)\n",
    "#         output = self.model(X_tensor)\n",
    "#         output_flat = output.view(-1)\n",
    "#         y_flat = y_tensor.view(-1)\n",
    "#         loss = self.reward_criterion(output_flat[-2:], y_flat)\n",
    "#         return loss\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 20\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": 0.005})\n",
    "\n",
    "# X, y = model.prepare_data(k=4)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With INNER LOOP but Improper classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         inner_lr = 0.01,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "#         self.inner_lr = inner_lr\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "#                 y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in tqdm(range(len(X))):\n",
    "#             if len(X[i])>self.num_support:\n",
    "#                 support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "#                 # Inner loop (adaptation)\n",
    "#                 adapted_model = self._inner_loop(support_X, support_y)\n",
    "#                 # Compute loss using the adapted model on query set\n",
    "#                 query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "#                 outer_losses.append(query_loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _inner_loop(self, support_X, support_y):\n",
    "#         adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "#                               self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "#         adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "#         inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "#         for _ in range(self.num_inner_steps):\n",
    "#             inner_optimizer.zero_grad()\n",
    "#             loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "#             inner_optimizer.step()\n",
    "\n",
    "#         return adapted_model\n",
    "\n",
    "#     def _compute_loss(self, model, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_class = [0 if y[i]==[1,0] else 1 for i in range(len(y))]\n",
    "#         y_tensor = torch.tensor(y_class, dtype=torch.long)  # Assuming y is class indices\n",
    "#         output = model(X_tensor)\n",
    "\n",
    "#         loss = self.reward_criterion(output, y_tensor)\n",
    "#         return loss\n",
    "\n",
    "#     def _split_support_query(self, X, y):\n",
    "#         num_samples = len(X)\n",
    "#         all_indices = np.arange(num_samples)\n",
    "#         # Randomly sample support indices\n",
    "#         support_indices = np.random.choice(num_samples, self.num_support, replace=False)\n",
    "#         query_indices = np.setdiff1d(all_indices, support_indices)\n",
    "#         support_X = X[support_indices]\n",
    "#         query_X = X[query_indices]\n",
    "#         # For y, we can simply use the same indices as for X, as it has a fixed length of 2\n",
    "#         support_y = [y] * self.num_support\n",
    "#         query_y = [y] * len(query_indices)\n",
    "\n",
    "#         return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 5\n",
    "# outer_lr = 0.001\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "# print('Preparing Data.')\n",
    "# # X, y = model.prepare_data(k=4)\n",
    "# print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
