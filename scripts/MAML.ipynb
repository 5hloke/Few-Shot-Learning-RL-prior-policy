{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import torch\n",
    "\n",
    "DATASETS = '../datasets/'\n",
    "\n",
    "def read_file(dir_name):\n",
    "    main_df = pd.DataFrame()\n",
    "    directory = DATASETS + dir_name\n",
    "    for filename in os.listdir(directory):\n",
    "        data = np.load(os.path.join(directory, filename))\n",
    "        data_dict = {}\n",
    "        for keys in data.keys():\n",
    "            data_dict[keys] = list(data[keys])\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        main_df = pd.concat([main_df, df])\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw/cls_basketball-v2\n",
      "mw/cls_push-v2\n",
      "mw/cls_door-open-v2\n",
      "mw/cls_window-open-v2\n",
      "mw/cls_peg-insert-side-v2\n",
      "mw/cls_reach-v2\n",
      "mw/cls_sweep-v2\n",
      "mw/cls_button_press_topdown-v2\n",
      "mw/cls_pick-place-v2\n",
      "mw/cls_drawer-close-v2\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for name in os.listdir(\"../datasets/mw\"):\n",
    "    inner_df = pd.DataFrame()\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        inner_df = pd.concat([inner_df, df])    \n",
    "    data.append(inner_df)\n",
    "data = np.array(data, dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PreferenceMAML:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ml10,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        output_size,\n",
    "        inner_lr = 0.01,\n",
    "        num_support=10,\n",
    "        num_query=10,\n",
    "        num_inner_steps=5,\n",
    "        k = 25,\n",
    "        num_tasks = 10,\n",
    "        episode_per_task = 1250,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.ml10 = ml10\n",
    "        self.reward_criterion =  nn.BCELoss()\n",
    "        self.num_support = num_support\n",
    "        self.num_query = num_query\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.inner_lr = inner_lr\n",
    "        self.k = k\n",
    "        self.num_tasks = num_tasks\n",
    "        self.episode_per_task = episode_per_task\n",
    "        self.num_segments = None\n",
    "        self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    def construct_episodes(self, ml10):\n",
    "        # episodes - n (tasks) x num_episode (each npz file)  , each cell is a dataframe of the episode \n",
    "        self.episodes = []\n",
    "        \n",
    "        for task in ml10:\n",
    "            task_episodes=[]\n",
    "            row_index = task[task['done'] == True].index.tolist()\n",
    "            prev=0\n",
    "            for x in row_index:\n",
    "                task_episodes.append(task[prev:x+1])\n",
    "                prev=x+1\n",
    "            task_episodes = np.array(task_episodes,dtype=object)\n",
    "            self.episodes.append(task_episodes)\n",
    "        self.episodes = np.array(self.episodes,dtype=object)\n",
    "        # return episodes\n",
    "\n",
    "    def form_sigma_groups(self, episode):\n",
    "        num_segments = int(episode.shape[0] / self.k)\n",
    "        # print(num_segments)\n",
    "        if num_segments != 0:\n",
    "            l_segment = np.array_split(episode.iloc[::-1], num_segments)\n",
    "            for i in range(len(l_segment)):\n",
    "                l_segment[i] = l_segment[i].iloc[::-1]\n",
    "            return l_segment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def compare_probabilities(self, sigma1, sigma2):\n",
    "        exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "        exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "        prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "        return [0] if prob > 0.5 else [1]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        episodes = self.episodes\n",
    "        # sigmas = self.form_sigma_groups(episodes, k)\n",
    "        sigmas = []\n",
    "        for task in episodes:\n",
    "            sigma = []\n",
    "            for episode in task:\n",
    "                segment = self.form_sigma_groups(episode)\n",
    "                # print(len(segment))\n",
    "                if segment is not None:\n",
    "                    sigma.append(segment)\n",
    "            # sigma = [self.form_sigma_groups(episode, k) for episode in task]\n",
    "            sigmas.append(sigma)\n",
    "        sigmas = np.array(sigmas, dtype=object)\n",
    "        all_lengths = [len(episode) for task in sigmas for episode in task]\n",
    "        self.num_segments = min(all_lengths)\n",
    "        \n",
    "        for task in sigmas:\n",
    "            task_list=[]\n",
    "            for episode in task:\n",
    "                ep_list=[]\n",
    "                for i in range(self.num_segments):\n",
    "                    y.append(episode[i][\"reward\"])\n",
    "                    episode[i]=episode[i].drop('reward', axis=1)\n",
    "                    ep_list.append(episode[i])\n",
    "                if(len(ep_list)==1):\n",
    "                    ep_list=ep_list[0]\n",
    "                else:\n",
    "                    ep_list=np.array(ep_list,dtype=object)\n",
    "                task_list.append(ep_list)\n",
    "            task_list = np.array(task_list, dtype=object)\n",
    "            X.append(task_list)\n",
    "        y=np.array(y,dtype=object)\n",
    "        X = np.array(X,dtype=object)\n",
    "\n",
    "        # All row vectors now, just transpose to make column vectors\n",
    "        \n",
    "\n",
    "            # sigmas = self.form_sigma_groups(episode, k)\n",
    "            # for _ in range(len(sigmas)):\n",
    "            #     sigma1 = sigmas[_][0]\n",
    "            #     sigma2 = sigmas[_][1]\n",
    "\n",
    "            #     obs_action_sigma1 = []\n",
    "            #     for row in sigma1:\n",
    "            #         obs_action = list(row['obs']) + list(row['action']) \n",
    "            #         obs_action_sigma1.append(obs_action)\n",
    "\n",
    "            #     obs_action_sigma2 = []\n",
    "            #     for row in sigma2:\n",
    "            #         obs_action = list(row['obs']) + list(row['action'])  \n",
    "            #         obs_action_sigma2.append(obs_action)\n",
    "\n",
    "            #     if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "            #         obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "            #     elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "            #         obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "            #     else:\n",
    "            #         continue\n",
    "\n",
    "            #     X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "            #     y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "        self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "    def _train_step(self, X, y):\n",
    "        self.optim.zero_grad()\n",
    "        loss = self._outer_step(X, y)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def _outer_step(self, X, y):\n",
    "        outer_losses = []\n",
    "        for i in tqdm(range(len(X))):\n",
    "            if len(X[i])>self.num_support:\n",
    "                support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "                # Inner loop (adaptation)\n",
    "                adapted_model = self._inner_loop(support_X, support_y)\n",
    "                # Compute loss using the adapted model on query set\n",
    "                query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "                outer_losses.append(query_loss)\n",
    "        return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "    def _inner_loop(self, support_X, support_y):\n",
    "        adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "                              self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "        adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "        inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "        for _ in range(self.num_inner_steps):\n",
    "            inner_optimizer.zero_grad()\n",
    "            loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "            loss.backward()\n",
    "            inner_optimizer.step()\n",
    "\n",
    "        return adapted_model\n",
    "    '''\n",
    "    R_E = \n",
    "    [\n",
    "        [\n",
    "            sigma_s1^E1, ..., sigma_s#^E1\n",
    "        ],\n",
    "        [\n",
    "            sigma_s1^E2, ..., sigma_s#^E2\n",
    "        ], ...,\n",
    "        [\n",
    "            sigma_s1^EN, ..., sigma_s#^EN\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    #self.k = segment lenght\n",
    "    def _compute_loss(self, model, X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)  \n",
    "        output_reward = model(X_tensor)\n",
    "        N_o, _ = output_reward.shape\n",
    "        out_mat = np.zeros(self.num_tasks, self.episode_per_tasks, self.num_segments)\n",
    "        y_mat = np.zeros(self.num_tasks, self.episode_per_tasks, self.num_segments)\n",
    "\n",
    "        T = self.episode_per_task*self.k*self.num_segments\n",
    "        for i in range(0, output_reward.shape[0], self.k):\n",
    "            ind = i % T\n",
    "            task_num = i // T\n",
    "            ep = ind // (self.num_segments * self.k)\n",
    "            seg = ind % (self.num_segments * self.k)\n",
    "            out_mat[task_num, ep, seg] = np.sum(output_reward[i : i+self.k])\n",
    "            y_mat[task_num, ep, seg ] = np.sum(y_tensor[i: i+self.k])\n",
    "        \n",
    "        loss = 0.0\n",
    "        for i in range(self.num_tasks):\n",
    "            for j in range(self.num_segments):\n",
    "                for k in range(j, self.num_segments):\n",
    "                    out_seg_j = out_mat[i, :, j].squeeze()\n",
    "                    out_seg_k = out_mat[i, :, k].squeeze()\n",
    "                    y_seg_j = y_mat[i, :, j].squeeze()\n",
    "                    y_seg_k = y_mat[i, :, k].squeeze() \n",
    "\n",
    "                    # comparison\n",
    "                    exp_j = np.exp(out_seg_j)\n",
    "                    exp_k = np.exp(out_seg_k)\n",
    "                    out_jk = exp_j / (exp_j + exp_k)\n",
    "                    if (y_seg_j >= y_seg_k):\n",
    "                        loss += -np.log(out_jk)\n",
    "                    else:\n",
    "                        loss += -np.log(1 - out_jk)\n",
    "        return loss\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "ml10 = data.copy()  \n",
    "input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 128\n",
    "output_size = 1\n",
    "num_epochs = 5\n",
    "outer_lr = 0.001\n",
    "\n",
    "model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "model.construct_episodes(ml10)\n",
    "print('Preparing Data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y stuff\n",
      "(12236,)\n",
      "(29,)\n",
      "[85      4.168999\n",
      " 86      4.377440\n",
      " 87      4.576863\n",
      " 88      4.762183\n",
      " 89      4.930076\n",
      " 90      5.072768\n",
      " 91      5.182332\n",
      " 92      5.254492\n",
      " 93      5.287608\n",
      " 94      5.285057\n",
      " 95      5.254955\n",
      " 96      5.210855\n",
      " 97      5.180713\n",
      " 98      5.192379\n",
      " 99      5.254183\n",
      " 100     5.364913\n",
      " 101     5.518336\n",
      " 102     5.703803\n",
      " 103     5.909175\n",
      " 104     6.122326\n",
      " 105     6.330786\n",
      " 106     6.523500\n",
      " 107     6.690452\n",
      " 108     6.824387\n",
      " 109     6.916635\n",
      " 110     6.968943\n",
      " 111     6.992448\n",
      " 112     6.999481\n",
      " 113    10.000000\n",
      " Name: reward, dtype: float32 195     5.395178\n",
      "                              196     5.352249\n",
      "                              197     5.290116\n",
      "                              198     5.238499\n",
      "                              199     5.231824\n",
      "                              200     5.281853\n",
      "                              201     5.388639\n",
      "                              202     5.545058\n",
      "                              203     5.736720\n",
      "                              204     5.947789\n",
      "                              205     6.163264\n",
      "                              206     6.370056\n",
      "                              207     6.556854\n",
      "                              208     6.715075\n",
      "                              209     6.833787\n",
      "                              210     6.909848\n",
      "                              211     6.953248\n",
      "                              212     6.975458\n",
      "                              213     6.985471\n",
      "                              214     6.989141\n",
      "                              215     6.989213\n",
      "                              216     6.986286\n",
      "                              217     6.982344\n",
      "                              218     6.981177\n",
      "                              219     6.984988\n",
      "                              220     6.992873\n",
      "                              221     6.999490\n",
      "                              222    10.000000\n",
      "                              Name: reward, dtype: float32\n",
      " 303     4.140177\n",
      " 304     4.378352\n",
      " 305     4.615999\n",
      " 306     4.848388\n",
      " 307     5.067054\n",
      " 308     5.261878\n",
      " 309     5.426098\n",
      " 310     5.555837\n",
      " 311     5.647617\n",
      " 312     5.696704\n",
      " 313     5.698862\n",
      " 314     5.658449\n",
      " 315     5.591928\n",
      " 316     5.531457\n",
      " 317     5.509769\n",
      " 318     5.541228\n",
      " 319     5.628977\n",
      " 320     5.768902\n",
      " 321     5.949157\n",
      " 322     6.152203\n",
      " 323     6.359958\n",
      " 324     6.554084\n",
      " 325     6.720260\n",
      " 326     6.850459\n",
      " 327     6.940043\n",
      " 328     6.987321\n",
      " 329    10.000000\n",
      " Name: reward, dtype: float32 ... 3880    0.000000e+00\n",
      "                                  3881    0.000000e+00\n",
      "                                  3882    0.000000e+00\n",
      "                                  3883    0.000000e+00\n",
      "                                  3884    0.000000e+00\n",
      "                                  3885    0.000000e+00\n",
      "                                  3886    0.000000e+00\n",
      "                                  3887    1.000000e+01\n",
      "                                  3888    0.000000e+00\n",
      "                                  3889    4.902848e-01\n",
      "                                  3890    4.079865e-01\n",
      "                                  3891    2.967224e-01\n",
      "                                  3892    1.687122e-01\n",
      "                                  3893    6.249629e-02\n",
      "                                  3894    1.260778e-02\n",
      "                                  3895    1.274526e-03\n",
      "                                  3896    6.268124e-05\n",
      "                                  3897    1.535392e-06\n",
      "                                  3898    1.917267e-08\n",
      "                                  3899    1.223648e-10\n",
      "                                  3900    3.990124e-13\n",
      "                                  3901    6.712264e-16\n",
      "                                  3902    4.735427e-19\n",
      "                                  3903    1.498527e-22\n",
      "                                  3904    2.810561e-26\n",
      "                                  3905    3.602223e-30\n",
      "                                  3906    2.519801e-34\n",
      "                                  3907    8.282956e-39\n",
      "                                  3908    1.247156e-43\n",
      "                                  3909    0.000000e+00\n",
      "                                  Name: reward, dtype: float32\n",
      " 3937    2.726718e-06\n",
      " 3938    1.058531e-06\n",
      " 3939    1.789202e-07\n",
      " 3940    2.057762e-08\n",
      " 3941    3.071069e-09\n",
      " 3942    7.671574e-10\n",
      " 3943    3.203958e-10\n",
      " 3944    1.858122e-10\n",
      " 3945    1.469384e-10\n",
      " 3946    1.849590e-10\n",
      " 3947    3.282035e-10\n",
      " 3948    4.704636e-10\n",
      " 3949    6.679124e-10\n",
      " 3950    1.261729e-09\n",
      " 3951    2.960912e-09\n",
      " 3952    7.622108e-09\n",
      " 3953    2.040867e-08\n",
      " 3954    5.758675e-08\n",
      " 3955    1.657118e-07\n",
      " 3956    4.846069e-07\n",
      " 3957    1.320842e-06\n",
      " 3958    3.100399e-06\n",
      " 3959    4.831671e-06\n",
      " 3960    5.764904e-06\n",
      " 3961    6.448492e-06\n",
      " 3962    8.147456e-06\n",
      " 3963    1.163767e-05\n",
      " Name: reward, dtype: float32 3964    1.447694e-05\n",
      "                              3965    1.725620e-05\n",
      "                              3966    1.888534e-05\n",
      "                              3967    1.943652e-05\n",
      "                              3968    1.911813e-05\n",
      "                              3969    1.000000e+01\n",
      "                              3970    0.000000e+00\n",
      "                              3971    4.922575e-01\n",
      "                              3972    4.131358e-01\n",
      "                              3973    2.976142e-01\n",
      "                              3974    1.653998e-01\n",
      "                              3975    6.142158e-02\n",
      "                              3976    1.288052e-02\n",
      "                              3977    1.386396e-03\n",
      "                              3978    7.458444e-05\n",
      "                              3979    2.026411e-06\n",
      "                              3980    2.771435e-08\n",
      "                              3981    1.858080e-10\n",
      "                              3982    6.071583e-13\n",
      "                              3983    9.861689e-16\n",
      "                              3984    7.049697e-19\n",
      "                              3985    2.433261e-22\n",
      "                              3986    4.444141e-26\n",
      "                              3987    5.326714e-30\n",
      "                              3988    3.925320e-34\n",
      "                              3989    1.548052e-38\n",
      "                              3990    2.984766e-43\n",
      "                              3991    0.000000e+00\n",
      "                              3992    0.000000e+00\n",
      "                              3993    0.000000e+00\n",
      "                              3994    0.000000e+00\n",
      "                              3995    0.000000e+00\n",
      "                              3996    0.000000e+00\n",
      "                              3997    0.000000e+00\n",
      "                              3998    1.401298e-45\n",
      "                              3999    6.740246e-43\n",
      "                              4000    4.531435e-40\n",
      "                              4001    2.568704e-37\n",
      "                              4002    1.043394e-34\n",
      "                              4003    2.821653e-32\n",
      "                              4004    5.392559e-30\n",
      "                              4005    8.729262e-28\n",
      "                              Name: reward, dtype: float32]\n",
      "X stuff\n",
      "(10,)\n",
      "(1226,)\n",
      "(29, 4)\n",
      "Data Preparation Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = model.prepare_data()\n",
    "print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw_valid/cls_shelf-place-v2\n",
      "mw_valid/cls_drawer-open-v2\n",
      "mw_valid/cls_lever-pull-v2\n",
      "mw_valid/cls_sweep-into-v2\n",
      "\n",
      "Test Accuracy: 0.6552772808586762\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "for name in os.listdir(\"../datasets/mw_valid\"):\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw_valid/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        test = pd.concat([data, df])\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "Test = PreferenceMAML(test, input_size, hidden_size1, hidden_size2, output_size)\n",
    "test_X, test_y = Test.prepare_data(k=4)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            X_tensor = torch.tensor(X[i], dtype=torch.float32)\n",
    "            output = model.model(X_tensor.unsqueeze(0))  \n",
    "            predictions.append(output.squeeze().numpy())  \n",
    "\n",
    "    preds = []\n",
    "    for _ in range(len(predictions)):\n",
    "        preds.append((np.array(predictions[_]).mean()))\n",
    "\n",
    "    pred_label = []\n",
    "    for i in range(len(preds)):\n",
    "        pred_label.append([0] if preds[i]>0.5 else [1])\n",
    "    \n",
    "    sum = 0\n",
    "    for _ in range(len(y)):\n",
    "        sum += pred_label[_]==y[_]\n",
    "    accuracy = sum/len(y)\n",
    "    return accuracy, pred_label\n",
    "\n",
    "test_accuracy, pred_labels = evaluate_model(model, test_X, test_y)\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without INNER LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis = 1))\n",
    "#                 y.append([self.compare_probabilities(sigma1, sigma2)]) \n",
    "\n",
    "#         return X, y\n",
    "\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in range(len(X)):\n",
    "#             loss = self._compute_loss(X[i], y[i])\n",
    "#             outer_losses.append(loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _compute_loss(self, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_tensor = torch.tensor([y], dtype=torch.float32)\n",
    "#         output = self.model(X_tensor)\n",
    "#         output_flat = output.view(-1)\n",
    "#         y_flat = y_tensor.view(-1)\n",
    "#         loss = self.reward_criterion(output_flat[-2:], y_flat)\n",
    "#         return loss\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 20\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": 0.005})\n",
    "\n",
    "# X, y = model.prepare_data(k=4)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With INNER LOOP but Improper classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         inner_lr = 0.01,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "#         self.inner_lr = inner_lr\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "#                 y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in tqdm(range(len(X))):\n",
    "#             if len(X[i])>self.num_support:\n",
    "#                 support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "#                 # Inner loop (adaptation)\n",
    "#                 adapted_model = self._inner_loop(support_X, support_y)\n",
    "#                 # Compute loss using the adapted model on query set\n",
    "#                 query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "#                 outer_losses.append(query_loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _inner_loop(self, support_X, support_y):\n",
    "#         adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "#                               self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "#         adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "#         inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "#         for _ in range(self.num_inner_steps):\n",
    "#             inner_optimizer.zero_grad()\n",
    "#             loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "#             inner_optimizer.step()\n",
    "\n",
    "#         return adapted_model\n",
    "\n",
    "#     def _compute_loss(self, model, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_class = [0 if y[i]==[1,0] else 1 for i in range(len(y))]\n",
    "#         y_tensor = torch.tensor(y_class, dtype=torch.long)  # Assuming y is class indices\n",
    "#         output = model(X_tensor)\n",
    "\n",
    "#         loss = self.reward_criterion(output, y_tensor)\n",
    "#         return loss\n",
    "\n",
    "#     def _split_support_query(self, X, y):\n",
    "#         num_samples = len(X)\n",
    "#         all_indices = np.arange(num_samples)\n",
    "#         # Randomly sample support indices\n",
    "#         support_indices = np.random.choice(num_samples, self.num_support, replace=False)\n",
    "#         query_indices = np.setdiff1d(all_indices, support_indices)\n",
    "#         support_X = X[support_indices]\n",
    "#         query_X = X[query_indices]\n",
    "#         # For y, we can simply use the same indices as for X, as it has a fixed length of 2\n",
    "#         support_y = [y] * self.num_support\n",
    "#         query_y = [y] * len(query_indices)\n",
    "\n",
    "#         return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 5\n",
    "# outer_lr = 0.001\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "# print('Preparing Data.')\n",
    "# # X, y = model.prepare_data(k=4)\n",
    "# print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
