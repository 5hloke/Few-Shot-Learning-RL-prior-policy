{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import torch\n",
    "\n",
    "DATASETS = '../datasets/'\n",
    "\n",
    "def read_file(dir_name):\n",
    "    main_df = pd.DataFrame()\n",
    "    directory = DATASETS + dir_name\n",
    "    for filename in os.listdir(directory):\n",
    "        data = np.load(os.path.join(directory, filename))\n",
    "        data_dict = {}\n",
    "        for keys in data.keys():\n",
    "            data_dict[keys] = list(data[keys])\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        main_df = pd.concat([main_df, df])\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mw/cls_sweep-v2\n",
      "mw/cls_push-v2\n",
      "mw/cls_door-open-v2\n",
      "mw/cls_peg-insert-side-v2\n",
      "mw/cls_drawer-close-v2\n",
      "mw/cls_basketball-v2\n",
      "mw/cls_reach-v2\n",
      "mw/cls_window-open-v2\n",
      "mw/cls_pick-place-v2\n",
      "mw/cls_button_press_topdown-v2\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for name in os.listdir(\"../datasets/mw\"):\n",
    "    inner_df = pd.DataFrame()\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        inner_df = pd.concat([inner_df, df])    \n",
    "    data.append(inner_df)\n",
    "data = np.array(data, dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=256, hidden_size2=256, hidden_size3=256, output_size = 2750):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.out = nn.Linear(hidden_size2, 1)\n",
    "    \n",
    "    # def forward_inner(self, x, parameters):\n",
    "    #     x = torch.relu(self.fc1(x, parameters['fc1.weight'], parameters['fc1.bias']))\n",
    "    #     x = torch.relu(self.fc2(x, parameters['fc2.weight'], parameters['fc2.bias']))\n",
    "    #     x = torch.tanh(self.out(x, parameters['out.weight'], parameters['out.bias']))\n",
    "    #     return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.out(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PreferenceMAML:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ml10,\n",
    "        input_size,\n",
    "        hidden_size1,\n",
    "        hidden_size2,\n",
    "        outer_lr = 0.0001,\n",
    "        inner_lr = 0.001,\n",
    "        num_support=10,\n",
    "        num_query=10,\n",
    "        num_inner_steps=5,\n",
    "        k = 25,\n",
    "        num_tasks = 10,\n",
    "        episode_per_task = 1250,\n",
    "        output_size = 2750,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.ml10 = ml10\n",
    "        self.reward_criterion =  nn.BCELoss()\n",
    "        self.num_support = num_support\n",
    "        self.num_query = num_query\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.inner_lr = inner_lr\n",
    "        self.outer_lr = outer_lr\n",
    "        self.k = k\n",
    "        self.num_tasks = num_tasks\n",
    "        self.episode_per_task = episode_per_task\n",
    "        self.num_segments = None\n",
    "        self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    def construct_episodes(self, ml10):\n",
    "        # episodes - n (tasks) x num_episode (each npz file)  , each cell is a dataframe of the episode \n",
    "        self.episodes = []\n",
    "        for task in ml10:\n",
    "            if(len(task)==0):\n",
    "                continue\n",
    "            task_episodes=[]\n",
    "            row_index = task[task['done'] == True].index.tolist()\n",
    "            prev=0\n",
    "            for x in row_index:\n",
    "                task_episodes.append(task[prev:x+1])\n",
    "                prev=x+1\n",
    "            task_episodes = np.array(task_episodes,dtype=object)\n",
    "            self.episodes.append(task_episodes)\n",
    "        self.episodes = np.array(self.episodes,dtype=object)\n",
    "        # return episodes\n",
    "\n",
    "    def form_sigma_groups(self, episode):\n",
    "        #num_segments = int(episode.shape[0] / self.k)\n",
    "        split_indices = np.arange(self.k, episode.shape[0], self.k)\n",
    "        # print(num_segments)\n",
    "        if len(split_indices) != 0:\n",
    "            l_segment = np.array_split(episode.iloc[::-1][:(self.k*(episode.shape[0] // self.k))], split_indices)\n",
    "            for i in range(len(l_segment)):\n",
    "                l_segment[i] = l_segment[i].iloc[::-1]\n",
    "            if(len(l_segment[-1])<25):\n",
    "                l_segment=l_segment[:-1]\n",
    "            return l_segment\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def compare_probabilities(self, sigma1, sigma2):\n",
    "        exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "        exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "        prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "        return [0] if prob > 0.5 else [1]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        episodes = self.episodes\n",
    "        # sigmas = self.form_sigma_groups(episodes, k)\n",
    "        sigmas = []\n",
    "        for task in episodes:\n",
    "            sigma = []\n",
    "            for episode in task:\n",
    "                segment = self.form_sigma_groups(episode)\n",
    "                # print(len(segment))\n",
    "                if segment is not None:\n",
    "                    sigma.append(segment)\n",
    "            # sigma = [self.form_sigma_groups(episode, k) for episode in task]\n",
    "            sigmas.append(sigma)\n",
    "        sigmas = np.array(sigmas, dtype=object)\n",
    "        all_lengths = [len(episode) for task in sigmas for episode in task]\n",
    "\n",
    "        self.num_segments = min(all_lengths)\n",
    "        if(self.num_segments<3):\n",
    "            self.num_segments=3\n",
    "        \n",
    "        for task in sigmas:\n",
    "            task_list=[]\n",
    "            for episode in task:\n",
    "                ep_list=[]\n",
    "                if(len(episode)<self.num_segments):\n",
    "                    continue\n",
    "                for i in range(self.num_segments):\n",
    "                    y.append(episode[i][\"reward\"])\n",
    "                    ep_list.append(episode[i].drop('reward', axis=1))\n",
    "                \n",
    "                task_list.append(ep_list)\n",
    "            task_list=np.array(task_list, dtype=object).reshape(-1,1) # convert row vector to col vector\n",
    "            X.append(task_list)\n",
    "        X_new=[]\n",
    "        task_counter = []\n",
    "        for task in X:\n",
    "            counter = 0\n",
    "            for i in range(0,len(task),4):\n",
    "                X_new.append(np.concatenate((task[i][0], task[i+1][0])))\n",
    "                counter += 1\n",
    "            task_counter.append(counter)\n",
    "\n",
    "        X = np.array(X_new, dtype=object)\n",
    "        task_counts = np.array(task_counter, dtype=object)\n",
    "        y=np.array(y,dtype=object)\n",
    "        y=y.flatten()\n",
    "\n",
    "        return X, y, task_counts\n",
    "    \n",
    "    def batchify(self, X, y, task_lengths, task_no, num=110):\n",
    "        # print(task_no)\n",
    "        if task_no == 0:\n",
    "            task_beg = 0  \n",
    "            task_end = task_lengths[0]\n",
    "        else:    \n",
    "            task_beg = np.sum(task_lengths[0:task_no])    \n",
    "            task_end = np.sum(task_lengths[0:task_no+1])\n",
    "        rand = random.sample(range(0,400), 110)\n",
    "        X_task = X[task_beg:task_end]\n",
    "        y_task = y[task_beg:task_end]\n",
    "        X_random = []\n",
    "        y_random = []\n",
    "        for r in rand:\n",
    "            X_random.append(X_task[r*25 : r*25+25])\n",
    "            y_random.append(y_task[r*25 : r*25+25])\n",
    "        X_random = np.array(X_random, dtype=np.float32)\n",
    "        y_random = np.array(y_random, dtype=np.float32)\n",
    "        return X_random.reshape(2750,43), y_random.reshape(2750,)\n",
    "    \n",
    "    def train(self, X, y, task_lengths, num_epochs):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr = self.outer_lr)\n",
    "        plt_x = np.arange(0, num_epochs)\n",
    "        plt_y = np.zeros(num_epochs)\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self._outer_step(self.model, X, y, task_lengths)\n",
    "            if loss is None:\n",
    "                return {}\n",
    "            plt_y[epoch] = loss\n",
    "            # print(\"Train Loss 1: \",plt_y[epoch])\n",
    "            # print(\"Train loss 2: \", loss)\n",
    "            if epoch%25 == 0:\n",
    "                plt.plot(plt_x[:epoch], plt_y[:epoch])\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Mean Loss\")\n",
    "                plt.show() \n",
    "                print(f\"Epoch: {epoch}, Loss: {plt_y[epoch]}\")\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "    def _outer_step(self, model, X, y, task_lengths):\n",
    "        outer_losses = []\n",
    "        for t in range(self.num_tasks):\n",
    "            X_b, y_b = self.batchify(X, y, task_lengths, t)\n",
    "            H, W = X_b.shape\n",
    "            inner_x = X_b[:H//2, :]\n",
    "            inner_y = y_b[:H//2]\n",
    "            outer_x = X_b[H//2:, :]\n",
    "            outer_y = y_b[H//2:]\n",
    "            weights = self._inner_loop(inner_x, inner_y, model = model)\n",
    "            # model_outer = copy.deepcopy(model)\n",
    "            # model_outer.load_state_dict(weights)\n",
    "            outer_losses.append(self._compute_loss(outer_x, outer_y, model, parameters=weights))\n",
    "        if (len(outer_losses) == 0):\n",
    "            return None\n",
    "        outer_loss = torch.mean(torch.stack(outer_losses))\n",
    "        # print(\"Outer Loss: \", loss)\n",
    "        return outer_loss\n",
    "\n",
    "\n",
    "            \n",
    "    def _inner_loop(self, X, y, model):\n",
    "        # parameters = {k: torch.clone(v) for k, v in model.ParameterDict()}\n",
    "        # model_inner = copy.deepcopy(model)\n",
    "        # opt_inner = optim.SGD(model_inner.parameters(), lr = self.inner_lr)\n",
    "        loss = self._compute_loss(X, y, model)\n",
    "        # grad = torch.autograd.grad(loss, parameters, allow_unused=True)\n",
    "        # for name, w in model_inner.named_parameters():\n",
    "        #     print(name, w)\n",
    "        # print(loss)\n",
    "        grad = grad = torch.autograd.grad(loss, model.parameters(), allow_unused=True)\n",
    "        # print(\"Grad: \")\n",
    "        # print(grad)\n",
    "        # raise Exception\n",
    "        # print(len(grad))\n",
    "        state_dict = model.state_dict()\n",
    "        idx = 0\n",
    "        for name, w in state_dict.items():\n",
    "            # print(grad[idx])\n",
    "            w_prime = w - self.inner_lr * grad[idx]\n",
    "            # raise Exception\n",
    "            idx += 1\n",
    "            w.copy_(w_prime)\n",
    "        return state_dict\n",
    "        # for name, w in model_inner.named_parameters():\n",
    "        #     print(name, w)\n",
    "        # raise Exception\n",
    "        # weights = list(map(lambda p: p[1] - self.inner_lr * p[0], zip(grad, parameters)))\n",
    "        # print(weights)\n",
    "\n",
    "        # print(\"Inner loss: \", loss)\n",
    "        # opt_inner.zero_grad()\n",
    "        # loss.backward()\n",
    "        \n",
    "        # opt_inner.step()\n",
    "\n",
    "        # grads = torch.autograd.grad(loss, parameters, create_graph=True)\n",
    "        #for j,k in enumerate(parameters.keys()):\n",
    "         #   parameters[k] = parameters[k] - self.inner_lr * grads[j]\n",
    "        # for name, w in model_inner.named_parameters():\n",
    "        #     if 'weight' in name:\n",
    "        #         w = w - self.inner_lr * grads\n",
    "\n",
    "        # parameters = parameters - self.inner_lr * grads\n",
    "        # return weights\n",
    "\n",
    "    '''\n",
    "    R_E = \n",
    "    [\n",
    "        [\n",
    "            sigma_s1^E1, ..., sigma_s#^E1\n",
    "        ],\n",
    "        [\n",
    "            sigma_s1^E2, ..., sigma_s#^E2\n",
    "        ], ...,\n",
    "        [\n",
    "            sigma_s1^EN, ..., sigma_s#^EN\n",
    "        ]\n",
    "    ]\n",
    "    '''\n",
    "    #self.k = segment lenght\n",
    "    def _compute_loss(self, X, y, model, parameters = None):\n",
    "        # print(X, y, X.shape, y.shape)\n",
    "        state_dict = model.state_dict()\n",
    "        if parameters is not None:\n",
    "            model.load_state_dict(parameters)\n",
    "        \n",
    "        X_tensor = torch.from_numpy(X)\n",
    "        y_tensor = torch.from_numpy(y)\n",
    "        # if parameters is not None:\n",
    "        #     output_reward = model.forward_inner(X_tensor, parameters)\n",
    "        # else:\n",
    "        output_reward = model(X_tensor)\n",
    "        N_o, _ = output_reward.shape\n",
    "        # print(output_reward.shape)\n",
    "        x =  y_tensor.shape[0]\n",
    "        N = x//self.k\n",
    "        output_reward = output_reward.reshape(N, self.k)\n",
    "        output_reward = torch.sum(output_reward, dim=1)\n",
    "        y_tensor = y_tensor.reshape(N, self.k)\n",
    "        y_tensor = torch.sum(y_tensor, dim=1)\n",
    "        loss = 0\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        #out_mat = np.exp(out_mat)\n",
    "        # out_logit = []\n",
    "        # out_y = []\n",
    "        loss = []\n",
    "        for i in range(N):\n",
    "            # sig_1 = output_reward[i]\n",
    "            # y_1 = y_tensor[i]\n",
    "            for j in range(i+1, N):\n",
    "                # sig_2 = output_reward[j]\n",
    "                # y_2 = y_tensor[j]\n",
    "                if y_tensor[i] > y_tensor[j]:\n",
    "                    loss.append(criterion(output_reward[j] - output_reward[i], torch.tensor(0.0, requires_grad= True)))\n",
    "                else:\n",
    "                    loss.append(criterion(output_reward[j] - output_reward[i], torch.tensor(1.0, requires_grad= True)))\n",
    "        loss = torch.sum(torch.stack(loss))\n",
    "        if parameters is not None:\n",
    "            model.load_state_dict(state_dict)\n",
    "        return loss\n",
    " # for i in range(N):\n",
    "        #     # print(torch.sum(output_reward[i*self.k:(i+1)*self.k]).detach().numpy())\n",
    "        #     out_mat[i, :] = torch.sum(output_reward[i*self.k:(i+1)*self.k]).detach().numpy()\n",
    "        #     y_mat[i, :] = torch.sum(y_tensor[i*self.k:(i+1)*self.k]).detach().numpy()\n",
    "  # if (model is not None) and (parameters is not None) :\n",
    "        #     print(\"Errors\")\n",
    "        #     return\n",
    "        # if model is not None:  \n",
    "        #     output_reward = model(X_tensor)\n",
    "        # elif parameters is not None:\n",
    "        #     output_reward = self.model(X_tensor, parameters)\n",
    "        # else:\n",
    "        #     output_reward = self.model(X_tensor)\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "ml10 = data.copy()  \n",
    "input_size = 43  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 256\n",
    "hidden_size3 = 256\n",
    "# hidden_size3 = 1024\n",
    "# hidden_size4 = 2075\n",
    "\n",
    "output_size = 1\n",
    "num_epochs = 5\n",
    "outer_lr = 0.0001\n",
    "\n",
    "model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, hidden_size3)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "model.construct_episodes(ml10)\n",
    "print('Preparing Data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, task_lengths = model.prepare_data()\n",
    "print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1090.9537353515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 1]], which is output 0 of AsStridedBackward0, is at version 31; expected version 30 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 193\u001b[0m, in \u001b[0;36mPreferenceMAML.train\u001b[0;34m(self, X, y, task_lengths, num_epochs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow() \n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplt_y[epoch]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 1]], which is output 0 of AsStridedBackward0, is at version 31; expected version 30 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "model.train(X, y, task_lengths, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "for name in os.listdir(\"../datasets/mw_valid\"):\n",
    "    if not (name.startswith('.')):\n",
    "        dir_name = 'mw_valid/'+name\n",
    "        print(dir_name)\n",
    "        df = read_file(dir_name)\n",
    "        test = pd.concat([data, df])\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "Test = PreferenceMAML(test, input_size, hidden_size1, hidden_size2, output_size)\n",
    "test_X, test_y = Test.prepare_data(k=4)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            X_tensor = torch.tensor(X[i], dtype=torch.float32)\n",
    "            output = model.model(X_tensor.unsqueeze(0))  \n",
    "            predictions.append(output.squeeze().numpy())  \n",
    "\n",
    "    preds = []\n",
    "    for _ in range(len(predictions)):\n",
    "        preds.append((np.array(predictions[_]).mean()))\n",
    "\n",
    "    pred_label = []\n",
    "    for i in range(len(preds)):\n",
    "        pred_label.append([0] if preds[i]>0.5 else [1])\n",
    "    \n",
    "    sum = 0\n",
    "    for _ in range(len(y)):\n",
    "        sum += pred_label[_]==y[_]\n",
    "    accuracy = sum/len(y)\n",
    "    return accuracy, pred_label\n",
    "\n",
    "test_accuracy, pred_labels = evaluate_model(model, test_X, test_y)\n",
    "print(f'\\nTest Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without INNER LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis = 1))\n",
    "#                 y.append([self.compare_probabilities(sigma1, sigma2)]) \n",
    "\n",
    "#         return X, y\n",
    "\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in range(len(X)):\n",
    "#             loss = self._compute_loss(X[i], y[i])\n",
    "#             outer_losses.append(loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _compute_loss(self, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_tensor = torch.tensor([y], dtype=torch.float32)\n",
    "#         output = self.model(X_tensor)\n",
    "#         output_flat = output.view(-1)\n",
    "#         y_flat = y_tensor.view(-1)\n",
    "#         loss = self.reward_criterion(output_flat[-2:], y_flat)\n",
    "#         return loss\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 20\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": 0.005})\n",
    "\n",
    "# X, y = model.prepare_data(k=4)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With INNER LOOP but Improper classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class PreferenceMAML:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         ml10,\n",
    "#         input_size,\n",
    "#         hidden_size1,\n",
    "#         hidden_size2,\n",
    "#         output_size,\n",
    "#         inner_lr = 0.01,\n",
    "#         num_support=10,\n",
    "#         num_query=10,\n",
    "#         num_inner_steps=5,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         self.ml10 = ml10\n",
    "#         self.reward_criterion =  nn.CrossEntropyLoss()\n",
    "#         self.num_support = num_support\n",
    "#         self.num_query = num_query\n",
    "#         self.num_inner_steps = num_inner_steps\n",
    "#         self.inner_lr = inner_lr\n",
    "\n",
    "#         self.model = Model(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "#     def construct_episodes(self):\n",
    "#         episodes = []\n",
    "#         episode = []\n",
    "#         for _, row in self.ml10.iterrows():\n",
    "#             episode.append(row)\n",
    "#             if row['done']:\n",
    "#                 episodes.append(episode)\n",
    "#                 episode = []\n",
    "#         return episodes\n",
    "\n",
    "#     def form_sigma_groups(self, episode, k):\n",
    "#         sigmas = []\n",
    "#         segments = []\n",
    "#         q, r = divmod(len(episode), k)\n",
    "#         for i in range(k):\n",
    "#             segments.append(episode[i*q+min(i,r) : (i+1)*q+min(i+1,r)])\n",
    "\n",
    "#         for i in range(k):\n",
    "#             sigma_i = segments[i]\n",
    "#             for j in range(i+1, k):\n",
    "#                 sigma_j = segments[j]\n",
    "\n",
    "#                 sigmas.append((sigma_i, sigma_j))\n",
    "#         return sigmas\n",
    "\n",
    "#     def compare_probabilities(self, sigma1, sigma2):\n",
    "#         exp_sum_rewards_sigma1 = np.exp(sum(row['reward'] for row in sigma1))\n",
    "#         exp_sum_rewards_sigma2 = np.exp(sum(row['reward'] for row in sigma2))\n",
    "#         prob = exp_sum_rewards_sigma1 / (exp_sum_rewards_sigma1 + exp_sum_rewards_sigma2)\n",
    "#         return [1,0] if prob > 0.5 else [0,1]\n",
    "\n",
    "#     def prepare_data(self, k):\n",
    "#         X = []\n",
    "#         y = []\n",
    "#         episodes = self.construct_episodes()\n",
    "#         for episode in episodes:\n",
    "#             sigmas = self.form_sigma_groups(episode, k)\n",
    "#             for _ in range(len(sigmas)):\n",
    "#                 sigma1 = sigmas[_][0]\n",
    "#                 sigma2 = sigmas[_][1]\n",
    "\n",
    "#                 obs_action_sigma1 = []\n",
    "#                 for row in sigma1:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma1.append(obs_action)\n",
    "\n",
    "#                 obs_action_sigma2 = []\n",
    "#                 for row in sigma2:\n",
    "#                     obs_action = list(row['obs']) + list(row['action'])  # Concatenate obs and action\n",
    "#                     obs_action_sigma2.append(obs_action)\n",
    "\n",
    "#                 if len(obs_action_sigma1) > len(obs_action_sigma2):\n",
    "#                     obs_action_sigma1 = obs_action_sigma1[1:]\n",
    "#                 elif len(obs_action_sigma1) < len(obs_action_sigma2):\n",
    "#                     obs_action_sigma2 = obs_action_sigma2[1:]\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 X.append(np.concatenate((obs_action_sigma1, obs_action_sigma2), axis=1))\n",
    "#                 y.append(self.compare_probabilities(sigma1, sigma2))\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "#     def setup_optimizers(self, optim_class, optim_kwargs):\n",
    "#         self.optim = optim_class(self.model.parameters(), **optim_kwargs)\n",
    "\n",
    "#     def _train_step(self, X, y):\n",
    "#         self.optim.zero_grad()\n",
    "#         loss = self._outer_step(X, y)\n",
    "#         loss.backward()\n",
    "#         self.optim.step()\n",
    "#         return loss.item()\n",
    "\n",
    "#     def _outer_step(self, X, y):\n",
    "#         outer_losses = []\n",
    "#         for i in tqdm(range(len(X))):\n",
    "#             if len(X[i])>self.num_support:\n",
    "#                 support_X, support_y, query_X, query_y = self._split_support_query(X[i], y[i])\n",
    "#                 # Inner loop (adaptation)\n",
    "#                 adapted_model = self._inner_loop(support_X, support_y)\n",
    "#                 # Compute loss using the adapted model on query set\n",
    "#                 query_loss = self._compute_loss(adapted_model, query_X, query_y)\n",
    "#                 outer_losses.append(query_loss)\n",
    "#         return torch.mean(torch.stack(outer_losses))\n",
    "\n",
    "#     def _inner_loop(self, support_X, support_y):\n",
    "#         adapted_model = Model(self.model.fc1.in_features, self.model.fc1.out_features,\n",
    "#                               self.model.fc2.out_features, self.model.fc3.out_features)\n",
    "#         adapted_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "#         inner_optimizer = optim.Adam(adapted_model.parameters(), lr=self.inner_lr)\n",
    "\n",
    "#         for _ in range(self.num_inner_steps):\n",
    "#             inner_optimizer.zero_grad()\n",
    "#             loss = self._compute_loss(adapted_model, support_X, support_y)\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "#             inner_optimizer.step()\n",
    "\n",
    "#         return adapted_model\n",
    "\n",
    "#     def _compute_loss(self, model, X, y):\n",
    "#         X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "#         y_class = [0 if y[i]==[1,0] else 1 for i in range(len(y))]\n",
    "#         y_tensor = torch.tensor(y_class, dtype=torch.long)  # Assuming y is class indices\n",
    "#         output = model(X_tensor)\n",
    "\n",
    "#         loss = self.reward_criterion(output, y_tensor)\n",
    "#         return loss\n",
    "\n",
    "#     def _split_support_query(self, X, y):\n",
    "#         num_samples = len(X)\n",
    "#         all_indices = np.arange(num_samples)\n",
    "#         # Randomly sample support indices\n",
    "#         support_indices = np.random.choice(num_samples, self.num_support, replace=False)\n",
    "#         query_indices = np.setdiff1d(all_indices, support_indices)\n",
    "#         support_X = X[support_indices]\n",
    "#         query_X = X[query_indices]\n",
    "#         # For y, we can simply use the same indices as for X, as it has a fixed length of 2\n",
    "#         support_y = [y] * self.num_support\n",
    "#         query_y = [y] * len(query_indices)\n",
    "\n",
    "#         return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "# ml10 = data.copy()  \n",
    "# input_size = 86  # Assuming obs has 39 numbers and action has 4 numbers * 2 for pair of sigmas\n",
    "# hidden_size1 = 128\n",
    "# hidden_size2 = 128\n",
    "# output_size = 2\n",
    "# num_epochs = 5\n",
    "# outer_lr = 0.001\n",
    "\n",
    "# model = PreferenceMAML(ml10, input_size, hidden_size1, hidden_size2, output_size)\n",
    "# model.setup_optimizers(optim.Adam, {\"lr\": outer_lr})\n",
    "\n",
    "# print('Preparing Data.')\n",
    "# # X, y = model.prepare_data(k=4)\n",
    "# print('Data Preparation Done.\\n')\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'\\nBeginning Training - Epoch [{epoch+1}/{num_epochs}]')\n",
    "#     loss = model._train_step(X, y)\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
